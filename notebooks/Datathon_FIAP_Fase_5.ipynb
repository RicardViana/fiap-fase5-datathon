{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxHUzQDVEeOD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import io\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, average_precision_score,\n",
        "    confusion_matrix, classification_report, roc_curve, precision_recall_curve\n",
        ")\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import KNNImputer, SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "    HAS_XGB = True\n",
        "except Exception:\n",
        "    HAS_XGB = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOtmJYo9Efh5"
      },
      "outputs": [],
      "source": [
        "# FUNÇÕES DE PREPARO\n",
        "\n",
        "def coerce_numeric(s):\n",
        "    return pd.to_numeric(s, errors=\"coerce\")\n",
        "def extrair_fase(valor):\n",
        "    if pd.isna(valor):\n",
        "        return np.nan\n",
        "    valor = str(valor).lower()\n",
        "    if \"alfa\" in valor:\n",
        "        return 0\n",
        "    m = re.search(r\"fase\\s*(\\d+)\", valor)\n",
        "    if m:\n",
        "        return int(m.group(1))\n",
        "    return np.nan\n",
        "\n",
        "\n",
        "def padronizar_genero(df):\n",
        "    df = df.copy()\n",
        "    if \"genero\" in df.columns:\n",
        "        df[\"genero\"] = df[\"genero\"].astype(str).str.strip().str.lower()\n",
        "        map_genero = {\n",
        "            \"menino\": \"masculino\",\n",
        "            \"masculino\": \"masculino\",\n",
        "            \"menina\": \"feminino\",\n",
        "            \"feminino\": \"feminino\"\n",
        "        }\n",
        "        df[\"genero\"] = df[\"genero\"].map(map_genero)\n",
        "    return df\n",
        "\n",
        "\n",
        "def padronizar_idade(df):\n",
        "    df = df.copy()\n",
        "    if \"idade\" not in df.columns:\n",
        "        return df\n",
        "\n",
        "    s = df[\"idade\"]\n",
        "    dt = pd.to_datetime(s, errors=\"coerce\")\n",
        "\n",
        "    idade_from_date = np.where(\n",
        "        dt.notna() & (dt.dt.year == 1900) & (dt.dt.month == 1),\n",
        "        dt.dt.day,\n",
        "        np.nan\n",
        "    )\n",
        "\n",
        "    idade_num = pd.to_numeric(s, errors=\"coerce\")\n",
        "    idade_final = pd.Series(idade_num, index=df.index)\n",
        "\n",
        "    mask = idade_final.isna() & ~pd.isna(idade_from_date)\n",
        "    idade_final.loc[mask] = idade_from_date[mask]\n",
        "\n",
        "    # faixa plausível\n",
        "    idade_final = idade_final.where(idade_final.between(6, 30))\n",
        "    df[\"idade\"] = idade_final.round()\n",
        "    return df\n",
        "\n",
        "\n",
        "def tratar_inde_2024(df):\n",
        "    df = df.copy()\n",
        "    if \"inde_2024\" in df.columns:\n",
        "        tmp = df[\"inde_2024\"].astype(str).str.strip().str.upper()\n",
        "        tmp = tmp.replace(\"INCLUIR\", np.nan)\n",
        "        df[\"inde_2024\"] = coerce_numeric(tmp)\n",
        "    return df\n",
        "\n",
        "\n",
        "def preparar_base(df, modo_treino: bool):\n",
        "    \"\"\"\n",
        "    modo_treino=True:\n",
        "      - cria target a partir de 'ian'\n",
        "      - remove vazamento (ian/defasagem)\n",
        "    modo_treino=False:\n",
        "      - não cria target\n",
        "      - remove vazamento se existir\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    df = padronizar_genero(df)\n",
        "    df = padronizar_idade(df)\n",
        "    df = tratar_inde_2024(df)\n",
        "\n",
        "    if \"fase_ideal\" in df.columns:\n",
        "        df[\"fase_ideal\"] = df[\"fase_ideal\"].apply(extrair_fase)\n",
        "\n",
        "    # Target (somente treino)\n",
        "    if modo_treino:\n",
        "        if \"ian\" not in df.columns:\n",
        "            raise ValueError(\"modo_treino=True exige coluna 'ian' para criar a target.\")\n",
        "        df[\"risco_defasagem_atual\"] = (pd.to_numeric(df[\"ian\"], errors=\"coerce\") <= 5).astype(int)\n",
        "\n",
        "    # Remover vazamento sempre que existir\n",
        "    df = df.drop(columns=[c for c in [\"ian\", \"defasagem\"] if c in df.columns], errors=\"ignore\")\n",
        "\n",
        "    # Remoções iguais ao treino (mantém seu padrão)\n",
        "    colunas_para_remover = [\"ra\",\n",
        "                            \"nome\",\n",
        "                            \"data_nasc\",\n",
        "                            \"escola\",\n",
        "                            \"avaliador_1\",\n",
        "                            \"avaliador_2\",\n",
        "                            \"avaliador_3\",\n",
        "                            \"avaliador_4\",\n",
        "                            \"avaliador_5\",\n",
        "                            \"avaliador_6\",\n",
        "                            \"rec_av1\",\n",
        "                            \"rec_av2\",\n",
        "                            \"rec_av3\",\n",
        "                            \"rec_av4\",\n",
        "                            \"rec_av5\",\n",
        "                            \"rec_av6\",\n",
        "                            \"rec_psicologia\",\n",
        "                            \"indicado\",\n",
        "                            \"atingiu_pv\",\n",
        "                            \"destaque_ieg\",\n",
        "                            \"destaque_ida\",\n",
        "                            \"destaque_ivp\",\n",
        "                            \"pedra_2020\",\n",
        "                            \"pedra_2021\",\n",
        "                            \"pedra_2022\",\n",
        "                            \"pedra_2023\",\n",
        "                            \"pedra_2024\",\n",
        "                            \"fase\",\n",
        "                            \"turma\",\n",
        "                            \"instituicao_ensino\",\n",
        "                            \"ativo_inativo\",\n",
        "                            \"cg\",\n",
        "                            \"cf\",\n",
        "                            \"ct\",\n",
        "                            \"inde_2024\"\n",
        "    ]\n",
        "    df = df.drop(columns=[c for c in colunas_para_remover if c in df.columns], errors=\"ignore\")\n",
        "\n",
        "    # Features extras\n",
        "    cols_acad = [c for c in [\"mat\",\"por\",\"ing\"] if c in df.columns]\n",
        "    if len(cols_acad) >= 2:\n",
        "        df[\"media_academica\"] = df[cols_acad].mean(axis=1)\n",
        "\n",
        "    cols_comp = [c for c in [\"iaa\",\"ieg\",\"ips\",\"ipp\"] if c in df.columns]\n",
        "    if len(cols_comp) >= 2:\n",
        "        df[\"media_comportamental\"] = df[cols_comp].mean(axis=1)\n",
        "\n",
        "    if (\"inde_2022\" in df.columns) and (\"inde_2023\" in df.columns):\n",
        "        df[\"delta_inde\"] = df[\"inde_2023\"] - df[\"inde_2022\"]\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def make_preprocess(X_train: pd.DataFrame) -> ColumnTransformer:\n",
        "    num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = [c for c in X_train.columns if c not in num_cols]\n",
        "\n",
        "    numeric_pipe = Pipeline(steps=[\n",
        "        (\"imputer\", KNNImputer(n_neighbors=7, weights=\"distance\")),\n",
        "        (\"scaler\", StandardScaler())\n",
        "    ])\n",
        "\n",
        "    categorical_pipe = Pipeline(steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "    ])\n",
        "\n",
        "    preprocess = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", numeric_pipe, num_cols),\n",
        "            (\"cat\", categorical_pipe, cat_cols),\n",
        "        ],\n",
        "        remainder=\"drop\"\n",
        "    )\n",
        "    return preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6eaDghBE7DT"
      },
      "outputs": [],
      "source": [
        "# 2) TREINO COMPLETO + TESTE + THRESHOLD + SALVAR ARQUIVOS\n",
        "# ============================================================\n",
        "\n",
        "def treinar_e_salvar(excel_path: str,\n",
        "                    out_model_path: str = \"modelo_passos_magicos.pkl\",\n",
        "                    out_cfg_path: str = \"config_passos_magicos.pkl\",\n",
        "                    seed: int = 42):\n",
        "\n",
        "    base = pd.read_excel(excel_path)\n",
        "    print(\"Shape original:\", base.shape)\n",
        "\n",
        "    base2 = preparar_base(base, modo_treino=True)\n",
        "    print(\"Shape após preparo:\", base2.shape)\n",
        "    print(\"Target balance:\\n\", base2[\"risco_defasagem_atual\"].value_counts())\n",
        "\n",
        "    if \"ano_pede\" not in base2.columns:\n",
        "        raise ValueError(\"Coluna 'ano_pede' não encontrada após preparo. Precisa dela para split temporal.\")\n",
        "\n",
        "    # Split temporal\n",
        "    train_df = base2[base2[\"ano_pede\"] < 2024].copy()\n",
        "    test_df  = base2[base2[\"ano_pede\"] == 2024].copy()\n",
        "\n",
        "    X_train = train_df.drop(columns=[\"risco_defasagem_atual\"])\n",
        "    y_train = train_df[\"risco_defasagem_atual\"].astype(int)\n",
        "\n",
        "    X_test = test_df.drop(columns=[\"risco_defasagem_atual\"])\n",
        "    y_test = test_df[\"risco_defasagem_atual\"].astype(int)\n",
        "\n",
        "    print(\"Treino:\", X_train.shape, \"Teste:\", X_test.shape)\n",
        "\n",
        "    preprocess = make_preprocess(X_train)\n",
        "\n",
        "    models = {\n",
        "        \"LogReg\": LogisticRegression(max_iter=2000, class_weight=\"balanced\"),\n",
        "        \"RandomForest\": RandomForestClassifier(\n",
        "            n_estimators=400, random_state=seed,\n",
        "            class_weight=\"balanced_subsample\"\n",
        "        ),\n",
        "        \"MLP\": MLPClassifier(\n",
        "            hidden_layer_sizes=(64, 32),\n",
        "            activation=\"relu\",\n",
        "            solver=\"adam\",\n",
        "            max_iter=500,\n",
        "            random_state=seed\n",
        "        ),\n",
        "    }\n",
        "\n",
        "    if HAS_XGB:\n",
        "        models[\"XGBoost\"] = XGBClassifier(\n",
        "            n_estimators=600,\n",
        "            learning_rate=0.05,\n",
        "            max_depth=4,\n",
        "            subsample=0.9,\n",
        "            colsample_bytree=0.9,\n",
        "            reg_lambda=1.0,\n",
        "            random_state=seed,\n",
        "            eval_metric=\"logloss\"\n",
        "        )\n",
        "    else:\n",
        "        print(\"XGBoost não disponível. Seguindo sem XGBoost.\")\n",
        "\n",
        "    # CV no treino\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "    scoring = {\"acc\": \"accuracy\", \"roc_auc\": \"roc_auc\", \"pr_auc\": \"average_precision\"}\n",
        "\n",
        "    print(\"\\n================= CV (TREINO) =================\")\n",
        "    cv_results = []\n",
        "    pipes = {}\n",
        "\n",
        "    for name, clf in models.items():\n",
        "        pipe = Pipeline(steps=[(\"prep\", preprocess), (\"model\", clf)])\n",
        "        pipes[name] = pipe\n",
        "\n",
        "        scores = cross_validate(\n",
        "            pipe, X_train, y_train,\n",
        "            cv=cv, scoring=scoring,\n",
        "            n_jobs=-1, return_train_score=False\n",
        "        )\n",
        "\n",
        "        row = {\n",
        "            \"model\": name,\n",
        "            \"acc_mean\": scores[\"test_acc\"].mean(),\n",
        "            \"acc_std\": scores[\"test_acc\"].std(),\n",
        "            \"roc_auc_mean\": scores[\"test_roc_auc\"].mean(),\n",
        "            \"roc_auc_std\": scores[\"test_roc_auc\"].std(),\n",
        "            \"pr_auc_mean\": scores[\"test_pr_auc\"].mean(),\n",
        "            \"pr_auc_std\": scores[\"test_pr_auc\"].std(),\n",
        "        }\n",
        "        cv_results.append(row)\n",
        "\n",
        "        print(f\"\\n{name}\")\n",
        "        print(f\"  ACC     : {row['acc_mean']:.4f} ± {row['acc_std']:.4f}\")\n",
        "        print(f\"  ROC AUC : {row['roc_auc_mean']:.4f} ± {row['roc_auc_std']:.4f}\")\n",
        "        print(f\"  PR AUC  : {row['pr_auc_mean']:.4f} ± {row['pr_auc_std']:.4f}\")\n",
        "\n",
        "    cv_df = pd.DataFrame(cv_results).sort_values(\"roc_auc_mean\", ascending=False)\n",
        "    print(\"\\nResumo CV:\")\n",
        "    print(cv_df)\n",
        "\n",
        "    # Teste final 2024\n",
        "    print(\"\\n================= TESTE FINAL (2024) =================\")\n",
        "    test_rows = []\n",
        "\n",
        "    def avaliar(nome, pipe):\n",
        "        pipe.fit(X_train, y_train)\n",
        "        y_proba = pipe.predict_proba(X_test)[:, 1]\n",
        "        y_pred = pipe.predict(X_test)\n",
        "\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        roc = roc_auc_score(y_test, y_proba)\n",
        "        pr  = average_precision_score(y_test, y_proba)\n",
        "\n",
        "        print(f\"\\n>>> {nome}\")\n",
        "        print(f\"ACC     : {acc:.4f}\")\n",
        "        print(f\"ROC AUC : {roc:.4f}\")\n",
        "        print(f\"PR AUC  : {pr:.4f}\")\n",
        "        print(\"\\nMatriz de confusão:\")\n",
        "        print(confusion_matrix(y_test, y_pred))\n",
        "        print(\"\\nClassification report:\")\n",
        "        print(classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "        return {\"model\": nome, \"acc\": acc, \"roc_auc\": roc, \"pr_auc\": pr}\n",
        "\n",
        "    for name, pipe in pipes.items():\n",
        "        test_rows.append(avaliar(name, pipe))\n",
        "\n",
        "    test_df_res = pd.DataFrame(test_rows).sort_values(\"roc_auc\", ascending=False)\n",
        "    print(\"\\nResumo TESTE (ordenado por ROC AUC):\")\n",
        "    print(test_df_res)\n",
        "\n",
        "    best_name = test_df_res.iloc[0][\"model\"]\n",
        "    best_pipe = pipes[best_name]\n",
        "    print(\"\\nMelhor modelo no TESTE:\", best_name)\n",
        "\n",
        "    # Ajuste threshold no MELHOR modelo do teste\n",
        "    best_pipe.fit(X_train, y_train)\n",
        "    y_proba_best = best_pipe.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    thresholds = np.linspace(0.10, 0.90, 17)\n",
        "    thr_rows = []\n",
        "    for t in thresholds:\n",
        "        y_pred_t = (y_proba_best >= t).astype(int)\n",
        "        report = classification_report(y_test, y_pred_t, output_dict=True, zero_division=0)\n",
        "        acc = accuracy_score(y_test, y_pred_t)\n",
        "        prec1 = report[\"1\"][\"precision\"]\n",
        "        rec1 = report[\"1\"][\"recall\"]\n",
        "        f11 = report[\"1\"][\"f1-score\"]\n",
        "        thr_rows.append([t, acc, prec1, rec1, f11])\n",
        "\n",
        "    thr_df = pd.DataFrame(thr_rows, columns=[\"threshold\",\"accuracy\",\"precision_risco\",\"recall_risco\",\"f1_risco\"])\n",
        "    print(\"\\nTabela de thresholds (classe RISCO=1):\")\n",
        "    print(thr_df)\n",
        "\n",
        "    best_thr_row = thr_df.sort_values(\"f1_risco\", ascending=False).iloc[0]\n",
        "    best_threshold = float(best_thr_row[\"threshold\"])\n",
        "\n",
        "    print(\"\\nMelhor threshold (por F1 da classe 1):\", best_threshold)\n",
        "    print(\"Linha escolhida:\\n\", best_thr_row)\n",
        "\n",
        "    # Salvar arquivos\n",
        "    joblib.dump(best_pipe, out_model_path)\n",
        "    joblib.dump({\"threshold\": best_threshold, \"best_model\": best_name}, out_cfg_path)\n",
        "\n",
        "    print(\"\\nArquivos salvos:\")\n",
        "    print(f\"- {out_model_path}  (pipeline completo)\")\n",
        "    print(f\"- {out_cfg_path}  (threshold + nome do modelo)\")\n",
        "\n",
        "    return best_name, best_threshold, cv_df, test_df_res, thr_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCAx_PXUFE_S",
        "outputId": "5292be98-4ca2-4e2f-a2bd-a583cf29b69b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape original: (3030, 54)\n",
            "Shape após preparo: (3030, 21)\n",
            "Target balance:\n",
            " risco_defasagem_atual\n",
            "1    1687\n",
            "0    1343\n",
            "Name: count, dtype: int64\n",
            "Treino: (1874, 20) Teste: (1156, 20)\n",
            "\n",
            "================= CV (TREINO) =================\n",
            "\n",
            "LogReg\n",
            "  ACC     : 0.9007 ± 0.0191\n",
            "  ROC AUC : 0.9427 ± 0.0147\n",
            "  PR AUC  : 0.9350 ± 0.0257\n",
            "\n",
            "RandomForest\n",
            "  ACC     : 0.9130 ± 0.0067\n",
            "  ROC AUC : 0.9709 ± 0.0048\n",
            "  PR AUC  : 0.9788 ± 0.0051\n",
            "\n",
            "MLP\n",
            "  ACC     : 0.9781 ± 0.0046\n",
            "  ROC AUC : 0.9937 ± 0.0027\n",
            "  PR AUC  : 0.9930 ± 0.0077\n",
            "\n",
            "XGBoost\n",
            "  ACC     : 0.9413 ± 0.0068\n",
            "  ROC AUC : 0.9849 ± 0.0039\n",
            "  PR AUC  : 0.9899 ± 0.0024\n",
            "\n",
            "Resumo CV:\n",
            "          model  acc_mean   acc_std  roc_auc_mean  roc_auc_std  pr_auc_mean  \\\n",
            "2           MLP  0.978122  0.004587      0.993687     0.002682     0.992992   \n",
            "3       XGBoost  0.941298  0.006789      0.984940     0.003881     0.989912   \n",
            "1  RandomForest  0.913017  0.006710      0.970873     0.004781     0.978837   \n",
            "0        LogReg  0.900733  0.019129      0.942723     0.014682     0.935038   \n",
            "\n",
            "   pr_auc_std  \n",
            "2    0.007720  \n",
            "3    0.002441  \n",
            "1    0.005079  \n",
            "0    0.025708  \n",
            "\n",
            "================= TESTE FINAL (2024) =================\n",
            "\n",
            ">>> LogReg\n",
            "ACC     : 0.6116\n",
            "ROC AUC : 0.6850\n",
            "PR AUC  : 0.6214\n",
            "\n",
            "Matriz de confusão:\n",
            "[[512 110]\n",
            " [339 195]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6016    0.8232    0.6952       622\n",
            "           1     0.6393    0.3652    0.4648       534\n",
            "\n",
            "    accuracy                         0.6116      1156\n",
            "   macro avg     0.6205    0.5942    0.5800      1156\n",
            "weighted avg     0.6191    0.6116    0.5888      1156\n",
            "\n",
            "\n",
            ">>> RandomForest\n",
            "ACC     : 0.5882\n",
            "ROC AUC : 0.7140\n",
            "PR AUC  : 0.6892\n",
            "\n",
            "Matriz de confusão:\n",
            "[[229 393]\n",
            " [ 83 451]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7340    0.3682    0.4904       622\n",
            "           1     0.5344    0.8446    0.6546       534\n",
            "\n",
            "    accuracy                         0.5882      1156\n",
            "   macro avg     0.6342    0.6064    0.5725      1156\n",
            "weighted avg     0.6418    0.5882    0.5662      1156\n",
            "\n",
            "\n",
            ">>> MLP\n",
            "ACC     : 0.5978\n",
            "ROC AUC : 0.6366\n",
            "PR AUC  : 0.5881\n",
            "\n",
            "Matriz de confusão:\n",
            "[[473 149]\n",
            " [316 218]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5995    0.7605    0.6704       622\n",
            "           1     0.5940    0.4082    0.4839       534\n",
            "\n",
            "    accuracy                         0.5978      1156\n",
            "   macro avg     0.5967    0.5843    0.5772      1156\n",
            "weighted avg     0.5970    0.5978    0.5843      1156\n",
            "\n",
            "\n",
            ">>> XGBoost\n",
            "ACC     : 0.5874\n",
            "ROC AUC : 0.6826\n",
            "PR AUC  : 0.6493\n",
            "\n",
            "Matriz de confusão:\n",
            "[[283 339]\n",
            " [138 396]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6722    0.4550    0.5427       622\n",
            "           1     0.5388    0.7416    0.6241       534\n",
            "\n",
            "    accuracy                         0.5874      1156\n",
            "   macro avg     0.6055    0.5983    0.5834      1156\n",
            "weighted avg     0.6106    0.5874    0.5803      1156\n",
            "\n",
            "\n",
            "Resumo TESTE (ordenado por ROC AUC):\n",
            "          model       acc   roc_auc    pr_auc\n",
            "1  RandomForest  0.588235  0.713995  0.689187\n",
            "0        LogReg  0.611592  0.685044  0.621416\n",
            "3       XGBoost  0.587370  0.682607  0.649284\n",
            "2           MLP  0.597751  0.636587  0.588063\n",
            "\n",
            "Melhor modelo no TESTE: RandomForest\n",
            "\n",
            "Tabela de thresholds (classe RISCO=1):\n",
            "    threshold  accuracy  precision_risco  recall_risco  f1_risco\n",
            "0        0.10  0.502595         0.481515      1.000000  0.650030\n",
            "1        0.15  0.507785         0.484134      1.000000  0.652413\n",
            "2        0.20  0.507785         0.484047      0.994382  0.651134\n",
            "3        0.25  0.517301         0.488827      0.983146  0.652985\n",
            "4        0.30  0.527682         0.494297      0.973783  0.655738\n",
            "5        0.35  0.538927         0.500493      0.951311  0.655907\n",
            "6        0.40  0.556228         0.510881      0.923221  0.657772\n",
            "7        0.45  0.583045         0.528634      0.898876  0.665742\n",
            "8        0.50  0.587370         0.533728      0.844569  0.654097\n",
            "9        0.55  0.595156         0.541667      0.803371  0.647059\n",
            "10       0.60  0.608131         0.555102      0.764045  0.643026\n",
            "11       0.65  0.629758         0.581040      0.711610  0.639731\n",
            "12       0.70  0.638408         0.601399      0.644195  0.622061\n",
            "13       0.75  0.638408         0.618852      0.565543  0.590998\n",
            "14       0.80  0.689446         0.785016      0.451311  0.573127\n",
            "15       0.85  0.636678         0.803191      0.282772  0.418283\n",
            "16       0.90  0.577855         0.838235      0.106742  0.189369\n",
            "\n",
            "Melhor threshold (por F1 da classe 1): 0.45000000000000007\n",
            "Linha escolhida:\n",
            " threshold          0.450000\n",
            "accuracy           0.583045\n",
            "precision_risco    0.528634\n",
            "recall_risco       0.898876\n",
            "f1_risco           0.665742\n",
            "Name: 7, dtype: float64\n",
            "\n",
            "Arquivos salvos:\n",
            "- modelo_passos_magicos.pkl  (pipeline completo)\n",
            "- config_passos_magicos.pkl  (threshold + nome do modelo)\n"
          ]
        }
      ],
      "source": [
        "MODO = \"treino\"  # \"treino\" ou \"app\"\n",
        "EXCEL_PATH = \"/content/Base de Dados PEDE.xlsx\"  # ajuste se necessário\n",
        "MODEL_PATH = \"modelo_passos_magicos.pkl\"\n",
        "CFG_PATH = \"config_passos_magicos.pkl\"\n",
        "\n",
        "if MODO == \"treino\":\n",
        "    treinar_e_salvar(EXCEL_PATH, MODEL_PATH, CFG_PATH)\n",
        "\n",
        "elif MODO == \"app\":\n",
        "    # Streamlit NÃO é ideal no Colab, mas em ambiente local funciona:\n",
        "    # streamlit run seu_arquivo.py\n",
        "    print(\"Modo app: rode em ambiente local com Streamlit.\")\n",
        "    print(\"Exemplo: streamlit run projeto_completo.py\")\n",
        "else:\n",
        "    raise ValueError(\"MODO inválido. Use 'treino' ou 'app'.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "passos-magicos-datathon (3.9.25)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.25"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
