{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vxHUzQDVEeOD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import io\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, average_precision_score,\n",
        "    confusion_matrix, classification_report, roc_curve, precision_recall_curve\n",
        ")\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import KNNImputer, SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "    HAS_XGB = True\n",
        "except Exception:\n",
        "    HAS_XGB = False\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qOtmJYo9Efh5"
      },
      "outputs": [],
      "source": [
        "# FUNÇÕES DE PREPARO\n",
        "\n",
        "def coerce_numeric(s):\n",
        "    return pd.to_numeric(s, errors=\"coerce\")\n",
        "def extrair_fase(valor):\n",
        "    if pd.isna(valor):\n",
        "        return np.nan\n",
        "    valor = str(valor).lower()\n",
        "    if \"alfa\" in valor:\n",
        "        return 0\n",
        "    m = re.search(r\"fase\\s*(\\d+)\", valor)\n",
        "    if m:\n",
        "        return int(m.group(1))\n",
        "    return np.nan\n",
        "\n",
        "\n",
        "def padronizar_genero(df):\n",
        "    df = df.copy()\n",
        "    if \"genero\" in df.columns:\n",
        "        df[\"genero\"] = df[\"genero\"].astype(str).str.strip().str.lower()\n",
        "        map_genero = {\n",
        "            \"menino\": \"masculino\",\n",
        "            \"masculino\": \"masculino\",\n",
        "            \"menina\": \"feminino\",\n",
        "            \"feminino\": \"feminino\"\n",
        "        }\n",
        "        df[\"genero\"] = df[\"genero\"].map(map_genero)\n",
        "    return df\n",
        "\n",
        "\n",
        "def padronizar_idade(df):\n",
        "    df = df.copy()\n",
        "    if \"idade\" not in df.columns:\n",
        "        return df\n",
        "\n",
        "    s = df[\"idade\"]\n",
        "    dt = pd.to_datetime(s, errors=\"coerce\")\n",
        "\n",
        "    idade_from_date = np.where(\n",
        "        dt.notna() & (dt.dt.year == 1900) & (dt.dt.month == 1),\n",
        "        dt.dt.day,\n",
        "        np.nan\n",
        "    )\n",
        "\n",
        "    idade_num = pd.to_numeric(s, errors=\"coerce\")\n",
        "    idade_final = pd.Series(idade_num, index=df.index)\n",
        "\n",
        "    mask = idade_final.isna() & ~pd.isna(idade_from_date)\n",
        "    idade_final.loc[mask] = idade_from_date[mask]\n",
        "\n",
        "    # faixa plausível\n",
        "    idade_final = idade_final.where(idade_final.between(6, 30))\n",
        "    df[\"idade\"] = idade_final.round()\n",
        "    return df\n",
        "\n",
        "\n",
        "def tratar_inde_2024(df):\n",
        "    df = df.copy()\n",
        "    if \"inde_2024\" in df.columns:\n",
        "        tmp = df[\"inde_2024\"].astype(str).str.strip().str.upper()\n",
        "        tmp = tmp.replace(\"INCLUIR\", np.nan)\n",
        "        df[\"inde_2024\"] = coerce_numeric(tmp)\n",
        "    return df\n",
        "\n",
        "\n",
        "def preparar_base(df, modo_treino: bool):\n",
        "    \"\"\"\n",
        "    modo_treino=True:\n",
        "      - cria target a partir de 'ian'\n",
        "      - remove vazamento (ian/defasagem)\n",
        "    modo_treino=False:\n",
        "      - não cria target\n",
        "      - remove vazamento se existir\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    df = padronizar_genero(df)\n",
        "    df = padronizar_idade(df)\n",
        "    df = tratar_inde_2024(df)\n",
        "\n",
        "    if \"fase_ideal\" in df.columns:\n",
        "        df[\"fase_ideal\"] = df[\"fase_ideal\"].apply(extrair_fase)\n",
        "\n",
        "    # Target (somente treino)\n",
        "    if modo_treino:\n",
        "        if \"ian\" not in df.columns:\n",
        "            raise ValueError(\"modo_treino=True exige coluna 'ian' para criar a target.\")\n",
        "        df[\"risco_defasagem_atual\"] = (pd.to_numeric(df[\"ian\"], errors=\"coerce\") <= 5).astype(int)\n",
        "\n",
        "    # Remover vazamento sempre que existir\n",
        "    df = df.drop(columns=[c for c in [\"ian\", \"defasagem\"] if c in df.columns], errors=\"ignore\")\n",
        "\n",
        "    # Remoções iguais ao treino (mantém seu padrão)\n",
        "    colunas_para_remover = [\"ra\",\n",
        "                            \"nome\",\n",
        "                            \"data_nasc\",\n",
        "                            \"escola\",\n",
        "                            \"avaliador_1\",\n",
        "                            \"avaliador_2\",\n",
        "                            \"avaliador_3\",\n",
        "                            \"avaliador_4\",\n",
        "                            \"avaliador_5\",\n",
        "                            \"avaliador_6\",\n",
        "                            \"rec_av1\",\n",
        "                            \"rec_av2\",\n",
        "                            \"rec_av3\",\n",
        "                            \"rec_av4\",\n",
        "                            \"rec_av5\",\n",
        "                            \"rec_av6\",\n",
        "                            \"rec_psicologia\",\n",
        "                            \"indicado\",\n",
        "                            \"atingiu_pv\",\n",
        "                            \"destaque_ieg\",\n",
        "                            \"destaque_ida\",\n",
        "                            \"destaque_ivp\",\n",
        "                            \"pedra_2020\",\n",
        "                            \"pedra_2021\",\n",
        "                            \"pedra_2022\",\n",
        "                            \"pedra_2023\",\n",
        "                            \"pedra_2024\",\n",
        "                            \"fase\",\n",
        "                            \"turma\",\n",
        "                            \"instituicao_ensino\",\n",
        "                            \"ativo_inativo\",\n",
        "                            \"cg\",\n",
        "                            \"cf\",\n",
        "                            \"ct\",\n",
        "                            \"inde_2024\"\n",
        "    ]\n",
        "    df = df.drop(columns=[c for c in colunas_para_remover if c in df.columns], errors=\"ignore\")\n",
        "\n",
        "    # Features extras\n",
        "    cols_acad = [c for c in [\"mat\",\"por\",\"ing\"] if c in df.columns]\n",
        "    if len(cols_acad) >= 2:\n",
        "        df[\"media_academica\"] = df[cols_acad].mean(axis=1)\n",
        "\n",
        "    cols_comp = [c for c in [\"iaa\",\"ieg\",\"ips\",\"ipp\"] if c in df.columns]\n",
        "    if len(cols_comp) >= 2:\n",
        "        df[\"media_comportamental\"] = df[cols_comp].mean(axis=1)\n",
        "\n",
        "    if (\"inde_2022\" in df.columns) and (\"inde_2023\" in df.columns):\n",
        "        df[\"delta_inde\"] = df[\"inde_2023\"] - df[\"inde_2022\"]\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def make_preprocess(X_train: pd.DataFrame) -> ColumnTransformer:\n",
        "    num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = [c for c in X_train.columns if c not in num_cols]\n",
        "\n",
        "    numeric_pipe = Pipeline(steps=[\n",
        "        (\"imputer\", KNNImputer(n_neighbors=7, weights=\"distance\")),\n",
        "        (\"scaler\", StandardScaler())\n",
        "    ])\n",
        "\n",
        "    categorical_pipe = Pipeline(steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "    ])\n",
        "\n",
        "    preprocess = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", numeric_pipe, num_cols),\n",
        "            (\"cat\", categorical_pipe, cat_cols),\n",
        "        ],\n",
        "        remainder=\"drop\"\n",
        "    )\n",
        "    return preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "C6eaDghBE7DT"
      },
      "outputs": [],
      "source": [
        "# 2) TREINO COMPLETO + TESTE + THRESHOLD + SALVAR ARQUIVOS\n",
        "# ============================================================\n",
        "\n",
        "def treinar_e_salvar(excel_path: str,\n",
        "                    out_model_path: str = \"modelo_passos_magicos.pkl\",\n",
        "                    out_cfg_path: str = \"config_passos_magicos.pkl\",\n",
        "                    seed: int = 42):\n",
        "\n",
        "    base = pd.read_excel(excel_path)\n",
        "    print(\"Shape original:\", base.shape)\n",
        "\n",
        "    base2 = preparar_base(base, modo_treino=True)\n",
        "    print(\"Shape após preparo:\", base2.shape)\n",
        "    print(\"Target balance:\\n\", base2[\"risco_defasagem_atual\"].value_counts())\n",
        "\n",
        "    if \"ano_pede\" not in base2.columns:\n",
        "        raise ValueError(\"Coluna 'ano_pede' não encontrada após preparo. Precisa dela para split temporal.\")\n",
        "\n",
        "    # Split temporal\n",
        "    train_df = base2[base2[\"ano_pede\"] < 2024].copy()\n",
        "    test_df  = base2[base2[\"ano_pede\"] == 2024].copy()\n",
        "\n",
        "    X_train = train_df.drop(columns=[\"risco_defasagem_atual\"])\n",
        "    y_train = train_df[\"risco_defasagem_atual\"].astype(int)\n",
        "\n",
        "    X_test = test_df.drop(columns=[\"risco_defasagem_atual\"])\n",
        "    y_test = test_df[\"risco_defasagem_atual\"].astype(int)\n",
        "\n",
        "    print(\"Treino:\", X_train.shape, \"Teste:\", X_test.shape)\n",
        "\n",
        "    preprocess = make_preprocess(X_train)\n",
        "\n",
        "    models = {\n",
        "        \"LogReg\": LogisticRegression(max_iter=2000, class_weight=\"balanced\"),\n",
        "        \"RandomForest\": RandomForestClassifier(\n",
        "            n_estimators=400, random_state=seed,\n",
        "            class_weight=\"balanced_subsample\"\n",
        "        ),\n",
        "        \"MLP\": MLPClassifier(\n",
        "            hidden_layer_sizes=(64, 32),\n",
        "            activation=\"relu\",\n",
        "            solver=\"adam\",\n",
        "            max_iter=500,\n",
        "            random_state=seed\n",
        "        ),\n",
        "    }\n",
        "\n",
        "    if HAS_XGB:\n",
        "        models[\"XGBoost\"] = XGBClassifier(\n",
        "            n_estimators=600,\n",
        "            learning_rate=0.05,\n",
        "            max_depth=4,\n",
        "            subsample=0.9,\n",
        "            colsample_bytree=0.9,\n",
        "            reg_lambda=1.0,\n",
        "            random_state=seed,\n",
        "            eval_metric=\"logloss\"\n",
        "        )\n",
        "    else:\n",
        "        print(\"XGBoost não disponível. Seguindo sem XGBoost.\")\n",
        "\n",
        "    # CV no treino\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "    scoring = {\"acc\": \"accuracy\", \"roc_auc\": \"roc_auc\", \"pr_auc\": \"average_precision\"}\n",
        "\n",
        "    print(\"\\n================= CV (TREINO) =================\")\n",
        "    cv_results = []\n",
        "    pipes = {}\n",
        "\n",
        "    for name, clf in models.items():\n",
        "        pipe = Pipeline(steps=[(\"prep\", preprocess), (\"model\", clf)])\n",
        "        pipes[name] = pipe\n",
        "\n",
        "        scores = cross_validate(\n",
        "            pipe, X_train, y_train,\n",
        "            cv=cv, scoring=scoring,\n",
        "            n_jobs=-1, return_train_score=False\n",
        "        )\n",
        "\n",
        "        row = {\n",
        "            \"model\": name,\n",
        "            \"acc_mean\": scores[\"test_acc\"].mean(),\n",
        "            \"acc_std\": scores[\"test_acc\"].std(),\n",
        "            \"roc_auc_mean\": scores[\"test_roc_auc\"].mean(),\n",
        "            \"roc_auc_std\": scores[\"test_roc_auc\"].std(),\n",
        "            \"pr_auc_mean\": scores[\"test_pr_auc\"].mean(),\n",
        "            \"pr_auc_std\": scores[\"test_pr_auc\"].std(),\n",
        "        }\n",
        "        cv_results.append(row)\n",
        "\n",
        "        print(f\"\\n{name}\")\n",
        "        print(f\"  ACC     : {row['acc_mean']:.4f} ± {row['acc_std']:.4f}\")\n",
        "        print(f\"  ROC AUC : {row['roc_auc_mean']:.4f} ± {row['roc_auc_std']:.4f}\")\n",
        "        print(f\"  PR AUC  : {row['pr_auc_mean']:.4f} ± {row['pr_auc_std']:.4f}\")\n",
        "\n",
        "    cv_df = pd.DataFrame(cv_results).sort_values(\"roc_auc_mean\", ascending=False)\n",
        "    print(\"\\nResumo CV:\")\n",
        "    print(cv_df)\n",
        "\n",
        "    # Teste final 2024\n",
        "    print(\"\\n================= TESTE FINAL (2024) =================\")\n",
        "    test_rows = []\n",
        "\n",
        "    def avaliar(nome, pipe):\n",
        "        pipe.fit(X_train, y_train)\n",
        "        y_proba = pipe.predict_proba(X_test)[:, 1]\n",
        "        y_pred = pipe.predict(X_test)\n",
        "\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        roc = roc_auc_score(y_test, y_proba)\n",
        "        pr  = average_precision_score(y_test, y_proba)\n",
        "\n",
        "        print(f\"\\n>>> {nome}\")\n",
        "        print(f\"ACC     : {acc:.4f}\")\n",
        "        print(f\"ROC AUC : {roc:.4f}\")\n",
        "        print(f\"PR AUC  : {pr:.4f}\")\n",
        "        print(\"\\nMatriz de confusão:\")\n",
        "        print(confusion_matrix(y_test, y_pred))\n",
        "        print(\"\\nClassification report:\")\n",
        "        print(classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "        return {\"model\": nome, \"acc\": acc, \"roc_auc\": roc, \"pr_auc\": pr}\n",
        "\n",
        "    for name, pipe in pipes.items():\n",
        "        test_rows.append(avaliar(name, pipe))\n",
        "\n",
        "    test_df_res = pd.DataFrame(test_rows).sort_values(\"roc_auc\", ascending=False)\n",
        "    print(\"\\nResumo TESTE (ordenado por ROC AUC):\")\n",
        "    print(test_df_res)\n",
        "\n",
        "    best_name = test_df_res.iloc[0][\"model\"]\n",
        "    best_pipe = pipes[best_name]\n",
        "    print(\"\\nMelhor modelo no TESTE:\", best_name)\n",
        "\n",
        "    # Ajuste threshold no MELHOR modelo do teste\n",
        "    best_pipe.fit(X_train, y_train)\n",
        "    y_proba_best = best_pipe.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    thresholds = np.linspace(0.10, 0.90, 17)\n",
        "    thr_rows = []\n",
        "    for t in thresholds:\n",
        "        y_pred_t = (y_proba_best >= t).astype(int)\n",
        "        report = classification_report(y_test, y_pred_t, output_dict=True, zero_division=0)\n",
        "        acc = accuracy_score(y_test, y_pred_t)\n",
        "        prec1 = report[\"1\"][\"precision\"]\n",
        "        rec1 = report[\"1\"][\"recall\"]\n",
        "        f11 = report[\"1\"][\"f1-score\"]\n",
        "        thr_rows.append([t, acc, prec1, rec1, f11])\n",
        "\n",
        "    thr_df = pd.DataFrame(thr_rows, columns=[\"threshold\",\"accuracy\",\"precision_risco\",\"recall_risco\",\"f1_risco\"])\n",
        "    print(\"\\nTabela de thresholds (classe RISCO=1):\")\n",
        "    print(thr_df)\n",
        "\n",
        "    best_thr_row = thr_df.sort_values(\"f1_risco\", ascending=False).iloc[0]\n",
        "    best_threshold = float(best_thr_row[\"threshold\"])\n",
        "\n",
        "    print(\"\\nMelhor threshold (por F1 da classe 1):\", best_threshold)\n",
        "    print(\"Linha escolhida:\\n\", best_thr_row)\n",
        "\n",
        "    # Salvar arquivos\n",
        "    joblib.dump(best_pipe, out_model_path)\n",
        "    joblib.dump({\"threshold\": best_threshold, \"best_model\": best_name}, out_cfg_path)\n",
        "\n",
        "    print(\"\\nArquivos salvos:\")\n",
        "    print(f\"- (pipeline completo)\")\n",
        "    print(f\"- (threshold + nome do modelo)\")\n",
        "\n",
        "    return best_name, best_threshold, cv_df, test_df_res, thr_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCAx_PXUFE_S",
        "outputId": "49d66ab6-312f-407d-a1dd-d5f8dec97b84"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "python-dotenv could not parse statement starting at line 15\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape original: (3030, 18)\n",
            "Shape após preparo: (3030, 19)\n",
            "Target balance:\n",
            " risco_defasagem_atual\n",
            "1    1687\n",
            "0    1343\n",
            "Name: count, dtype: int64\n",
            "Treino: (1874, 18) Teste: (1156, 18)\n",
            "\n",
            "================= CV (TREINO) =================\n",
            "\n",
            "LogReg\n",
            "  ACC     : 0.8927 ± 0.0096\n",
            "  ROC AUC : 0.9394 ± 0.0101\n",
            "  PR AUC  : 0.9568 ± 0.0118\n",
            "\n",
            "RandomForest\n",
            "  ACC     : 0.8389 ± 0.0189\n",
            "  ROC AUC : 0.9122 ± 0.0093\n",
            "  PR AUC  : 0.9340 ± 0.0092\n",
            "\n",
            "MLP\n",
            "  ACC     : 0.9899 ± 0.0062\n",
            "  ROC AUC : 0.9969 ± 0.0022\n",
            "  PR AUC  : 0.9986 ± 0.0009\n",
            "\n",
            "XGBoost\n",
            "  ACC     : 0.9370 ± 0.0132\n",
            "  ROC AUC : 0.9772 ± 0.0081\n",
            "  PR AUC  : 0.9827 ± 0.0077\n",
            "\n",
            "Resumo CV:\n",
            "          model  acc_mean   acc_std  roc_auc_mean  roc_auc_std  pr_auc_mean  \\\n",
            "2           MLP  0.989861  0.006174      0.996912     0.002174     0.998643   \n",
            "3       XGBoost  0.937045  0.013200      0.977159     0.008055     0.982677   \n",
            "0        LogReg  0.892740  0.009631      0.939360     0.010099     0.956788   \n",
            "1  RandomForest  0.838863  0.018940      0.912180     0.009282     0.934021   \n",
            "\n",
            "   pr_auc_std  \n",
            "2    0.000942  \n",
            "3    0.007743  \n",
            "0    0.011806  \n",
            "1    0.009169  \n",
            "\n",
            "================= TESTE FINAL (2024) =================\n",
            "\n",
            ">>> LogReg\n",
            "ACC     : 0.5874\n",
            "ROC AUC : 0.6028\n",
            "PR AUC  : 0.5866\n",
            "\n",
            "Matriz de confusão:\n",
            "[[505 117]\n",
            " [360 174]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5838    0.8119    0.6792       622\n",
            "           1     0.5979    0.3258    0.4218       534\n",
            "\n",
            "    accuracy                         0.5874      1156\n",
            "   macro avg     0.5909    0.5689    0.5505      1156\n",
            "weighted avg     0.5903    0.5874    0.5603      1156\n",
            "\n",
            "\n",
            ">>> RandomForest\n",
            "ACC     : 0.5614\n",
            "ROC AUC : 0.6026\n",
            "PR AUC  : 0.5843\n",
            "\n",
            "Matriz de confusão:\n",
            "[[315 307]\n",
            " [200 334]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6117    0.5064    0.5541       622\n",
            "           1     0.5211    0.6255    0.5685       534\n",
            "\n",
            "    accuracy                         0.5614      1156\n",
            "   macro avg     0.5664    0.5659    0.5613      1156\n",
            "weighted avg     0.5698    0.5614    0.5608      1156\n",
            "\n",
            "\n",
            ">>> MLP\n",
            "ACC     : 0.5597\n",
            "ROC AUC : 0.5471\n",
            "PR AUC  : 0.5247\n",
            "\n",
            "Matriz de confusão:\n",
            "[[475 147]\n",
            " [362 172]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5675    0.7637    0.6511       622\n",
            "           1     0.5392    0.3221    0.4033       534\n",
            "\n",
            "    accuracy                         0.5597      1156\n",
            "   macro avg     0.5533    0.5429    0.5272      1156\n",
            "weighted avg     0.5544    0.5597    0.5366      1156\n",
            "\n",
            "\n",
            ">>> XGBoost\n",
            "ACC     : 0.5692\n",
            "ROC AUC : 0.5582\n",
            "PR AUC  : 0.5346\n",
            "\n",
            "Matriz de confusão:\n",
            "[[401 221]\n",
            " [277 257]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5914    0.6447    0.6169       622\n",
            "           1     0.5377    0.4813    0.5079       534\n",
            "\n",
            "    accuracy                         0.5692      1156\n",
            "   macro avg     0.5646    0.5630    0.5624      1156\n",
            "weighted avg     0.5666    0.5692    0.5666      1156\n",
            "\n",
            "\n",
            "Resumo TESTE (ordenado por ROC AUC):\n",
            "          model       acc   roc_auc    pr_auc\n",
            "0        LogReg  0.587370  0.602819  0.586623\n",
            "1  RandomForest  0.561419  0.602605  0.584298\n",
            "3       XGBoost  0.569204  0.558153  0.534555\n",
            "2           MLP  0.559689  0.547083  0.524739\n",
            "\n",
            "Melhor modelo no TESTE: LogReg\n",
            "\n",
            "Tabela de thresholds (classe RISCO=1):\n",
            "    threshold  accuracy  precision_risco  recall_risco  f1_risco\n",
            "0        0.10  0.587370         0.566434      0.455056  0.504673\n",
            "1        0.15  0.582180         0.564232      0.419476  0.481203\n",
            "2        0.20  0.584775         0.571429      0.404494  0.473684\n",
            "3        0.25  0.582180         0.571031      0.383895  0.459127\n",
            "4        0.30  0.587370         0.584071      0.370787  0.453608\n",
            "5        0.35  0.586505         0.584848      0.361423  0.446759\n",
            "6        0.40  0.587370         0.590476      0.348315  0.438163\n",
            "7        0.45  0.591696         0.603333      0.338951  0.434053\n",
            "8        0.50  0.587370         0.597938      0.325843  0.421818\n",
            "9        0.55  0.586505         0.602190      0.308989  0.408416\n",
            "10       0.60  0.589965         0.615385      0.299625  0.403023\n",
            "11       0.65  0.591696         0.624000      0.292135  0.397959\n",
            "12       0.70  0.589965         0.626050      0.279026  0.386010\n",
            "13       0.75  0.589100         0.632287      0.264045  0.372523\n",
            "14       0.80  0.588235         0.636792      0.252809  0.361930\n",
            "15       0.85  0.587370         0.647668      0.234082  0.343879\n",
            "16       0.90  0.587370         0.657459      0.222846  0.332867\n",
            "\n",
            "Melhor threshold (por F1 da classe 1): 0.1\n",
            "Linha escolhida:\n",
            " threshold          0.100000\n",
            "accuracy           0.587370\n",
            "precision_risco    0.566434\n",
            "recall_risco       0.455056\n",
            "f1_risco           0.504673\n",
            "Name: 0, dtype: float64\n",
            "\n",
            "Arquivos salvos:\n",
            "- (pipeline completo)\n",
            "- (threshold + nome do modelo)\n"
          ]
        }
      ],
      "source": [
        "# Localiza e carrega as variáveis do arquivo .env automaticamente\n",
        "load_dotenv(find_dotenv())\n",
        "\n",
        "# Puxa o caminho da variável de ambiente\n",
        "data_path = os.getenv(\"RAW_DATA_PATH\")\n",
        "models = os.getenv(\"MODELS\")\n",
        "\n",
        "MODO = \"treino\"  # \"treino\" ou \"app\"\n",
        "EXCEL_PATH = data_path \n",
        "MODEL_PATH = f\"{models}modelo_passos_magicos.pkl\"\n",
        "CFG_PATH = f\"{models}config_passos_magicos.pkl\"\n",
        "\n",
        "if MODO == \"treino\":\n",
        "    treinar_e_salvar(EXCEL_PATH, MODEL_PATH, CFG_PATH)\n",
        "\n",
        "elif MODO == \"app\":\n",
        "    # Streamlit NÃO é ideal no Colab, mas em ambiente local funciona:\n",
        "    # streamlit run seu_arquivo.py\n",
        "    print(\"Modo app: rode em ambiente local com Streamlit.\")\n",
        "    print(\"Exemplo: streamlit run projeto_completo.py\")\n",
        "else:\n",
        "    raise ValueError(\"MODO inválido. Use 'treino' ou 'app'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "QIccjv3oFHoY",
        "outputId": "5b4e7f3d-9fa5-41e0-ddbc-bb8481e4be70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Threshold:  0.1\n"
          ]
        }
      ],
      "source": [
        "pipe = joblib.load(f'{models}modelo_passos_magicos.pkl')\n",
        "cfg = joblib.load(f'{models}config_passos_magicos.pkl')\n",
        "\n",
        "threshold = cfg['threshold']\n",
        "print('Threshold: ', threshold)\n",
        "\n",
        "base = pd.read_excel(data_path)\n",
        "\n",
        "base_prep = preparar_base(base, modo_treino=False)\n",
        "\n",
        "sample = base_prep.sample(10, random_state=42)\n",
        "\n",
        "proba = pipe.predict_proba(sample)[:, 1]\n",
        "pred = (proba >= threshold).astype(int)\n",
        "\n",
        "sample['proba'] = proba\n",
        "sample['pred'] = pred\n",
        "\n",
        "sample\n",
        "\n",
        "processed_path = os.getenv(\"PROCESSED\")\n",
        "output_file = os.path.join(processed_path, \"sample_predicoes.xlsx\")\n",
        "sample.to_excel(output_file, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpcDJtV-5x29",
        "outputId": "aa070695-f1d6-44dc-fc90-4ead77e0d226"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['prep', 'model']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(pipe.named_steps.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "HUp8hWWZ4AZx",
        "outputId": "6903e178-71ff-4391-af99-b74e7e44fbf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      feature  importance\n",
            "2              num__inde_2022    5.271833\n",
            "3              num__inde_2023    4.102627\n",
            "5                    num__iaa    3.401025\n",
            "1               num__ano_pede    2.667250\n",
            "6                    num__ieg    2.246977\n",
            "7                    num__ips    2.179712\n",
            "0             num__Unnamed: 0    1.853061\n",
            "16            num__delta_inde    1.797100\n",
            "15  num__media_comportamental    1.598446\n",
            "13                   num__ipv    1.416159\n",
            "8                    num__ipp    1.412128\n",
            "9                    num__ida    0.725197\n",
            "10                   num__mat    0.645902\n",
            "14       num__media_academica    0.548667\n",
            "11                   num__por    0.497636\n"
          ]
        }
      ],
      "source": [
        "model = pipe.named_steps['model']\n",
        "\n",
        "if hasattr(model, 'feature_importances_'):\n",
        "    importances = model.feature_importances_\n",
        "elif hasattr(model, 'coef_'):\n",
        "    importances = np.abs(model.coef_[0])\n",
        "else:\n",
        "    importances = None\n",
        "    print(\"Este modelo não suporta extração de importância de variáveis.\")\n",
        "\n",
        "if importances is not None:\n",
        "    features = pipe.named_steps['prep'].get_feature_names_out()\n",
        "    imp = pd.DataFrame({\n",
        "        'feature': features,\n",
        "        'importance': importances\n",
        "    }).sort_values('importance', ascending=False)\n",
        "\n",
        "    print(imp.head(15))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "passos-magicos-datathon (3.9.25)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.25"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
