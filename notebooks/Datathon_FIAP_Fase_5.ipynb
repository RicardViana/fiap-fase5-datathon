{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vxHUzQDVEeOD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import io\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, average_precision_score,\n",
        "    confusion_matrix, classification_report, roc_curve, precision_recall_curve\n",
        ")\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import KNNImputer, SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "    HAS_XGB = True\n",
        "except Exception:\n",
        "    HAS_XGB = False\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qOtmJYo9Efh5"
      },
      "outputs": [],
      "source": [
        "# FUNÇÕES DE PREPARO\n",
        "\n",
        "def coerce_numeric(s):\n",
        "    return pd.to_numeric(s, errors=\"coerce\")\n",
        "def extrair_fase(valor):\n",
        "    if pd.isna(valor):\n",
        "        return np.nan\n",
        "    valor = str(valor).lower()\n",
        "    if \"alfa\" in valor:\n",
        "        return 0\n",
        "    m = re.search(r\"fase\\s*(\\d+)\", valor)\n",
        "    if m:\n",
        "        return int(m.group(1))\n",
        "    return np.nan\n",
        "\n",
        "\n",
        "def padronizar_genero(df):\n",
        "    df = df.copy()\n",
        "    if \"genero\" in df.columns:\n",
        "        df[\"genero\"] = df[\"genero\"].astype(str).str.strip().str.lower()\n",
        "        map_genero = {\n",
        "            \"menino\": \"masculino\",\n",
        "            \"masculino\": \"masculino\",\n",
        "            \"menina\": \"feminino\",\n",
        "            \"feminino\": \"feminino\"\n",
        "        }\n",
        "        df[\"genero\"] = df[\"genero\"].map(map_genero)\n",
        "    return df\n",
        "\n",
        "\n",
        "def padronizar_idade(df):\n",
        "    df = df.copy()\n",
        "    if \"idade\" not in df.columns:\n",
        "        return df\n",
        "\n",
        "    s = df[\"idade\"]\n",
        "    dt = pd.to_datetime(s, errors=\"coerce\")\n",
        "\n",
        "    idade_from_date = np.where(\n",
        "        dt.notna() & (dt.dt.year == 1900) & (dt.dt.month == 1),\n",
        "        dt.dt.day,\n",
        "        np.nan\n",
        "    )\n",
        "\n",
        "    idade_num = pd.to_numeric(s, errors=\"coerce\")\n",
        "    idade_final = pd.Series(idade_num, index=df.index)\n",
        "\n",
        "    mask = idade_final.isna() & ~pd.isna(idade_from_date)\n",
        "    idade_final.loc[mask] = idade_from_date[mask]\n",
        "\n",
        "    # faixa plausível\n",
        "    idade_final = idade_final.where(idade_final.between(6, 30))\n",
        "    df[\"idade\"] = idade_final.round()\n",
        "    return df\n",
        "\n",
        "\n",
        "def tratar_inde_2024(df):\n",
        "    df = df.copy()\n",
        "    if \"inde_2024\" in df.columns:\n",
        "        tmp = df[\"inde_2024\"].astype(str).str.strip().str.upper()\n",
        "        tmp = tmp.replace(\"INCLUIR\", np.nan)\n",
        "        df[\"inde_2024\"] = coerce_numeric(tmp)\n",
        "    return df\n",
        "\n",
        "\n",
        "def preparar_base(df, modo_treino: bool):\n",
        "    \"\"\"\n",
        "    modo_treino=True:\n",
        "      - cria target a partir de 'ian'\n",
        "      - remove vazamento (ian/defasagem)\n",
        "    modo_treino=False:\n",
        "      - não cria target\n",
        "      - remove vazamento se existir\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    df = padronizar_genero(df)\n",
        "    df = padronizar_idade(df)\n",
        "    df = tratar_inde_2024(df)\n",
        "\n",
        "    if \"fase_ideal\" in df.columns:\n",
        "        df[\"fase_ideal\"] = df[\"fase_ideal\"].apply(extrair_fase)\n",
        "\n",
        "    # Target (somente treino)\n",
        "    if modo_treino:\n",
        "        if \"ian\" not in df.columns:\n",
        "            raise ValueError(\"modo_treino=True exige coluna 'ian' para criar a target.\")\n",
        "        df[\"risco_defasagem_atual\"] = (pd.to_numeric(df[\"ian\"], errors=\"coerce\") <= 5).astype(int)\n",
        "\n",
        "    # Remover vazamento sempre que existir\n",
        "    df = df.drop(columns=[c for c in [\"ian\", \"defasagem\"] if c in df.columns], errors=\"ignore\")\n",
        "\n",
        "    # Remoções iguais ao treino (mantém seu padrão)\n",
        "    colunas_para_remover = [\"ra\",\n",
        "                            \"nome\",\n",
        "                            \"data_nasc\",\n",
        "                            \"escola\",\n",
        "                            \"avaliador_1\",\n",
        "                            \"avaliador_2\",\n",
        "                            \"avaliador_3\",\n",
        "                            \"avaliador_4\",\n",
        "                            \"avaliador_5\",\n",
        "                            \"avaliador_6\",\n",
        "                            \"rec_av1\",\n",
        "                            \"rec_av2\",\n",
        "                            \"rec_av3\",\n",
        "                            \"rec_av4\",\n",
        "                            \"rec_av5\",\n",
        "                            \"rec_av6\",\n",
        "                            \"rec_psicologia\",\n",
        "                            \"indicado\",\n",
        "                            \"atingiu_pv\",\n",
        "                            \"destaque_ieg\",\n",
        "                            \"destaque_ida\",\n",
        "                            \"destaque_ivp\",\n",
        "                            \"pedra_2020\",\n",
        "                            \"pedra_2021\",\n",
        "                            \"pedra_2022\",\n",
        "                            \"pedra_2023\",\n",
        "                            \"pedra_2024\",\n",
        "                            \"fase\",\n",
        "                            \"turma\",\n",
        "                            \"instituicao_ensino\",\n",
        "                            \"ativo_inativo\",\n",
        "                            \"cg\",\n",
        "                            \"cf\",\n",
        "                            \"ct\",\n",
        "                            \"inde_2024\"\n",
        "    ]\n",
        "    df = df.drop(columns=[c for c in colunas_para_remover if c in df.columns], errors=\"ignore\")\n",
        "\n",
        "    # Features extras\n",
        "    cols_acad = [c for c in [\"mat\",\"por\",\"ing\"] if c in df.columns]\n",
        "    if len(cols_acad) >= 2:\n",
        "        df[\"media_academica\"] = df[cols_acad].mean(axis=1)\n",
        "\n",
        "    cols_comp = [c for c in [\"iaa\",\"ieg\",\"ips\",\"ipp\"] if c in df.columns]\n",
        "    if len(cols_comp) >= 2:\n",
        "        df[\"media_comportamental\"] = df[cols_comp].mean(axis=1)\n",
        "\n",
        "    if (\"inde_2022\" in df.columns) and (\"inde_2023\" in df.columns):\n",
        "        df[\"delta_inde\"] = df[\"inde_2023\"] - df[\"inde_2022\"]\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def make_preprocess(X_train: pd.DataFrame) -> ColumnTransformer:\n",
        "    num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = [c for c in X_train.columns if c not in num_cols]\n",
        "\n",
        "    numeric_pipe = Pipeline(steps=[\n",
        "        (\"imputer\", KNNImputer(n_neighbors=7, weights=\"distance\")),\n",
        "        (\"scaler\", StandardScaler())\n",
        "    ])\n",
        "\n",
        "    categorical_pipe = Pipeline(steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "    ])\n",
        "\n",
        "    preprocess = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", numeric_pipe, num_cols),\n",
        "            (\"cat\", categorical_pipe, cat_cols),\n",
        "        ],\n",
        "        remainder=\"drop\"\n",
        "    )\n",
        "    return preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "C6eaDghBE7DT"
      },
      "outputs": [],
      "source": [
        "# 2) TREINO COMPLETO + TESTE + THRESHOLD + SALVAR ARQUIVOS\n",
        "# ============================================================\n",
        "\n",
        "def treinar_e_salvar(excel_path: str,\n",
        "                    out_model_path: str = \"modelo_passos_magicos.pkl\",\n",
        "                    out_cfg_path: str = \"config_passos_magicos.pkl\",\n",
        "                    seed: int = 42):\n",
        "\n",
        "    base = pd.read_excel(excel_path)\n",
        "    print(\"Shape original:\", base.shape)\n",
        "\n",
        "    base2 = preparar_base(base, modo_treino=True)\n",
        "    print(\"Shape após preparo:\", base2.shape)\n",
        "    print(\"Target balance:\\n\", base2[\"risco_defasagem_atual\"].value_counts())\n",
        "\n",
        "    if \"ano_pede\" not in base2.columns:\n",
        "        raise ValueError(\"Coluna 'ano_pede' não encontrada após preparo. Precisa dela para split temporal.\")\n",
        "\n",
        "    # Split temporal\n",
        "    train_df = base2[base2[\"ano_pede\"] < 2024].copy()\n",
        "    test_df  = base2[base2[\"ano_pede\"] == 2024].copy()\n",
        "\n",
        "    X_train = train_df.drop(columns=[\"risco_defasagem_atual\"])\n",
        "    y_train = train_df[\"risco_defasagem_atual\"].astype(int)\n",
        "\n",
        "    X_test = test_df.drop(columns=[\"risco_defasagem_atual\"])\n",
        "    y_test = test_df[\"risco_defasagem_atual\"].astype(int)\n",
        "\n",
        "    print(\"Treino:\", X_train.shape, \"Teste:\", X_test.shape)\n",
        "\n",
        "    preprocess = make_preprocess(X_train)\n",
        "\n",
        "    models = {\n",
        "        \"LogReg\": LogisticRegression(max_iter=2000, class_weight=\"balanced\"),\n",
        "        \"RandomForest\": RandomForestClassifier(\n",
        "            n_estimators=400, random_state=seed,\n",
        "            class_weight=\"balanced_subsample\"\n",
        "        ),\n",
        "        \"MLP\": MLPClassifier(\n",
        "            hidden_layer_sizes=(64, 32),\n",
        "            activation=\"relu\",\n",
        "            solver=\"adam\",\n",
        "            max_iter=500,\n",
        "            random_state=seed\n",
        "        ),\n",
        "    }\n",
        "\n",
        "    if HAS_XGB:\n",
        "        models[\"XGBoost\"] = XGBClassifier(\n",
        "            n_estimators=600,\n",
        "            learning_rate=0.05,\n",
        "            max_depth=4,\n",
        "            subsample=0.9,\n",
        "            colsample_bytree=0.9,\n",
        "            reg_lambda=1.0,\n",
        "            random_state=seed,\n",
        "            eval_metric=\"logloss\"\n",
        "        )\n",
        "    else:\n",
        "        print(\"XGBoost não disponível. Seguindo sem XGBoost.\")\n",
        "\n",
        "    # CV no treino\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "    scoring = {\"acc\": \"accuracy\", \"roc_auc\": \"roc_auc\", \"pr_auc\": \"average_precision\"}\n",
        "\n",
        "    print(\"\\n================= CV (TREINO) =================\")\n",
        "    cv_results = []\n",
        "    pipes = {}\n",
        "\n",
        "    for name, clf in models.items():\n",
        "        pipe = Pipeline(steps=[(\"prep\", preprocess), (\"model\", clf)])\n",
        "        pipes[name] = pipe\n",
        "\n",
        "        scores = cross_validate(\n",
        "            pipe, X_train, y_train,\n",
        "            cv=cv, scoring=scoring,\n",
        "            n_jobs=-1, return_train_score=False\n",
        "        )\n",
        "\n",
        "        row = {\n",
        "            \"model\": name,\n",
        "            \"acc_mean\": scores[\"test_acc\"].mean(),\n",
        "            \"acc_std\": scores[\"test_acc\"].std(),\n",
        "            \"roc_auc_mean\": scores[\"test_roc_auc\"].mean(),\n",
        "            \"roc_auc_std\": scores[\"test_roc_auc\"].std(),\n",
        "            \"pr_auc_mean\": scores[\"test_pr_auc\"].mean(),\n",
        "            \"pr_auc_std\": scores[\"test_pr_auc\"].std(),\n",
        "        }\n",
        "        cv_results.append(row)\n",
        "\n",
        "        print(f\"\\n{name}\")\n",
        "        print(f\"  ACC     : {row['acc_mean']:.4f} ± {row['acc_std']:.4f}\")\n",
        "        print(f\"  ROC AUC : {row['roc_auc_mean']:.4f} ± {row['roc_auc_std']:.4f}\")\n",
        "        print(f\"  PR AUC  : {row['pr_auc_mean']:.4f} ± {row['pr_auc_std']:.4f}\")\n",
        "\n",
        "    cv_df = pd.DataFrame(cv_results).sort_values(\"roc_auc_mean\", ascending=False)\n",
        "    print(\"\\nResumo CV:\")\n",
        "    print(cv_df)\n",
        "\n",
        "    # Teste final 2024\n",
        "    print(\"\\n================= TESTE FINAL (2024) =================\")\n",
        "    test_rows = []\n",
        "\n",
        "    def avaliar(nome, pipe):\n",
        "        pipe.fit(X_train, y_train)\n",
        "        y_proba = pipe.predict_proba(X_test)[:, 1]\n",
        "        y_pred = pipe.predict(X_test)\n",
        "\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        roc = roc_auc_score(y_test, y_proba)\n",
        "        pr  = average_precision_score(y_test, y_proba)\n",
        "\n",
        "        print(f\"\\n>>> {nome}\")\n",
        "        print(f\"ACC     : {acc:.4f}\")\n",
        "        print(f\"ROC AUC : {roc:.4f}\")\n",
        "        print(f\"PR AUC  : {pr:.4f}\")\n",
        "        print(\"\\nMatriz de confusão:\")\n",
        "        print(confusion_matrix(y_test, y_pred))\n",
        "        print(\"\\nClassification report:\")\n",
        "        print(classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "        return {\"model\": nome, \"acc\": acc, \"roc_auc\": roc, \"pr_auc\": pr}\n",
        "\n",
        "    for name, pipe in pipes.items():\n",
        "        test_rows.append(avaliar(name, pipe))\n",
        "\n",
        "    test_df_res = pd.DataFrame(test_rows).sort_values(\"roc_auc\", ascending=False)\n",
        "    print(\"\\nResumo TESTE (ordenado por ROC AUC):\")\n",
        "    print(test_df_res)\n",
        "\n",
        "    best_name = test_df_res.iloc[0][\"model\"]\n",
        "    best_pipe = pipes[best_name]\n",
        "    print(\"\\nMelhor modelo no TESTE:\", best_name)\n",
        "\n",
        "    # Ajuste threshold no MELHOR modelo do teste\n",
        "    best_pipe.fit(X_train, y_train)\n",
        "    y_proba_best = best_pipe.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    thresholds = np.linspace(0.10, 0.90, 17)\n",
        "    thr_rows = []\n",
        "    for t in thresholds:\n",
        "        y_pred_t = (y_proba_best >= t).astype(int)\n",
        "        report = classification_report(y_test, y_pred_t, output_dict=True, zero_division=0)\n",
        "        acc = accuracy_score(y_test, y_pred_t)\n",
        "        prec1 = report[\"1\"][\"precision\"]\n",
        "        rec1 = report[\"1\"][\"recall\"]\n",
        "        f11 = report[\"1\"][\"f1-score\"]\n",
        "        thr_rows.append([t, acc, prec1, rec1, f11])\n",
        "\n",
        "    thr_df = pd.DataFrame(thr_rows, columns=[\"threshold\",\"accuracy\",\"precision_risco\",\"recall_risco\",\"f1_risco\"])\n",
        "    print(\"\\nTabela de thresholds (classe RISCO=1):\")\n",
        "    print(thr_df)\n",
        "\n",
        "    best_thr_row = thr_df.sort_values(\"f1_risco\", ascending=False).iloc[0]\n",
        "    best_threshold = float(best_thr_row[\"threshold\"])\n",
        "\n",
        "    print(\"\\nMelhor threshold (por F1 da classe 1):\", best_threshold)\n",
        "    print(\"Linha escolhida:\\n\", best_thr_row)\n",
        "\n",
        "    # Salvar arquivos\n",
        "    joblib.dump(best_pipe, out_model_path)\n",
        "    joblib.dump({\"threshold\": best_threshold, \"best_model\": best_name}, out_cfg_path)\n",
        "\n",
        "    print(\"\\nArquivos salvos:\")\n",
        "    print(f\"- {out_model_path}  (pipeline completo)\")\n",
        "    print(f\"- {out_cfg_path}  (threshold + nome do modelo)\")\n",
        "\n",
        "    return best_name, best_threshold, cv_df, test_df_res, thr_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCAx_PXUFE_S",
        "outputId": "49d66ab6-312f-407d-a1dd-d5f8dec97b84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape original: (860, 42)\n"
          ]
        }
      ],
      "source": [
        "# Localiza e carrega as variáveis do arquivo .env automaticamente\n",
        "load_dotenv(find_dotenv())\n",
        "\n",
        "# Puxa o caminho da variável de ambiente\n",
        "data_path = os.getenv(\"RAW_DATA_PATH\")\n",
        "\n",
        "\n",
        "MODO = \"treino\"  # \"treino\" ou \"app\"\n",
        "EXCEL_PATH = data_path \n",
        "MODEL_PATH = \"modelo_passos_magicos.pkl\"\n",
        "CFG_PATH = \"config_passos_magicos.pkl\"\n",
        "\n",
        "if MODO == \"treino\":\n",
        "    treinar_e_salvar(EXCEL_PATH, MODEL_PATH, CFG_PATH)\n",
        "\n",
        "elif MODO == \"app\":\n",
        "    # Streamlit NÃO é ideal no Colab, mas em ambiente local funciona:\n",
        "    # streamlit run seu_arquivo.py\n",
        "    print(\"Modo app: rode em ambiente local com Streamlit.\")\n",
        "    print(\"Exemplo: streamlit run projeto_completo.py\")\n",
        "else:\n",
        "    raise ValueError(\"MODO inválido. Use 'treino' ou 'app'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "QIccjv3oFHoY",
        "outputId": "5b4e7f3d-9fa5-41e0-ddbc-bb8481e4be70"
      },
      "outputs": [],
      "source": [
        "pipe = joblib.load('modelo_passos_magicos.pkl')\n",
        "cfg = joblib.load('config_passos_magicos.pkl')\n",
        "\n",
        "threshold = cfg['threshold']\n",
        "print('Threshold: ', threshold)\n",
        "\n",
        "base = pd.read_excel(\"/content/Base de Dados PEDE.xlsx\")\n",
        "\n",
        "base_prep = preparar_base(base, modo_treino=False)\n",
        "\n",
        "sample = base_prep.sample(10, random_state=42)\n",
        "\n",
        "proba = pipe.predict_proba(sample)[:, 1]\n",
        "pred = (proba >= threshold).astype(int)\n",
        "\n",
        "sample['proba'] = proba\n",
        "sample['pred'] = pred\n",
        "\n",
        "sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpcDJtV-5x29",
        "outputId": "aa070695-f1d6-44dc-fc90-4ead77e0d226"
      },
      "outputs": [],
      "source": [
        "list(pipe.named_steps.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "HUp8hWWZ4AZx",
        "outputId": "6903e178-71ff-4391-af99-b74e7e44fbf0"
      },
      "outputs": [],
      "source": [
        "model = pipe.named_steps['model']\n",
        "\n",
        "importances = model.feature_importances_\n",
        "\n",
        "features = pipe.named_steps['prep'].get_feature_names_out()\n",
        "\n",
        "imp = pd.DataFrame({\n",
        "    'feature': features,\n",
        "    'importance': importances\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "imp.head(15)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "passos-magicos-datathon (3.9.25)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.25"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
